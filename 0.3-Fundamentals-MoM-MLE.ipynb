{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation\n",
    "\n",
    "给定来自某个总体的代表性数据样本，我们可能需要估计表征总体的分布的参数。我们在下面讨论估计量的属性和以下估计方法：\n",
    "\n",
    "1. 矩法。\n",
    "2. 最大似然估计 (MLE)。\n",
    "3. 最大后验概率估计 (MAP)。\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of estimators\n",
    "\n",
    "什么是好的估算器？我们可能想要一个指向我们正在估计的参数的估计器，并且在该值附近变化不大。通常，这两种愿望之间存在权衡。几个定义：\n",
    "\n",
    "### Consistency\n",
    "\n",
    "一致性是\n",
    "\n",
    "$$P(|\\theta_n-\\theta |>0) \\to 0 \\text{ as } n \\to \\infty$$\n",
    "\n",
    "换句话说，这表明随着样本变大，估计器的概率收敛到 \\\\(\\theta\\\\)。 \n",
    "\n",
    "### Bias\n",
    "\n",
    "\\\\(\\theta_n\\\\) 是无偏的，如果\n",
    "\n",
    "$$E(\\theta_n)=\\theta$$\n",
    "\n",
    "基本上，如果估计量以真实为中心，则它是无偏的。\n",
    "\n",
    "## Efficency \n",
    "\n",
    "在所有无偏估计量中具有最低可能方差的估计量被认为是有效的。\n",
    "\n",
    "### Mean squared error\n",
    "\n",
    "结合方差和偏差，我们得到了称为均方误差 (MSE) 的估计器质量的度量：\n",
    "\n",
    "$$MSE = variance + bias^2$$\n",
    "\n",
    "MSE 是衡量准确度（范围）和精确度（位置）之间的权衡。\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Method of moments\n",
    "\n",
    "矩法相当于将总体矩与样本矩相匹配。基本上，我们使用以下给出的有限近似：\n",
    "\n",
    "$$E[f] = \\int f(x)^r p(x) dx \\approx \\frac{1}{N} \\sum f(x)^r p(x)$$ \n",
    "\n",
    "where \\\\(f(x)=x\\\\) and \\\\(r=1\\\\), this amounts to \n",
    "\n",
    "$$\\mu \\approx \\bar{x}$$\n",
    "\n",
    "我们可以选择使用哪种矩，但是，所需的矩数量将等于我们要估计的参数数量。例如，假设我们希望估计由伯努利分布给出的抛硬币实验的成功概率。我们知道：\n",
    "\n",
    "\\\\(X_i \\sim Bern(\\theta)\\\\), 我们定义了正面为 x = 1:\n",
    "\n",
    "$$P_X(x;\\theta) = \n",
    "\\begin{cases}\n",
    "    \\theta, \\text{for x = 1} \\\\\n",
    "    1 - \\theta, \\text{ for x = 0} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "或者，我们可以将其写为：\n",
    "\n",
    "$$f(x;\\theta) = \\theta^x(1-\\theta)^{(1-x)}$$\n",
    "\n",
    "对于这个实验，让我们假设我们正在收集 N=20 次掷硬币并最终得到数据：{1,1,0,1,1,1,1,0,1,0,1,0,1, 1,0,0,1,1,1,0}（13 个正面）。\n",
    "\n",
    "我们正在寻求估计均值和方差。\n",
    "\n",
    "对于总体：\n",
    "\n",
    "$$E[X] = \\sum_x x f(x) = \\sum_x x [\\theta^x(1-\\theta)^{(1-x)}] = 0\\ast(1-\\theta) + 1\\ast\\theta = \\theta$$\n",
    "\n",
    "$$Var(X) = \\theta(1-\\theta)$$ \n",
    "\n",
    "由此，我们看到我们只需要估计一个参数，因为方差是均值的函数。\n",
    "\n",
    "因此，我们可以将第一个样本时刻与总体时刻相匹配以获得我们的估计：\n",
    "\n",
    "$$\\hat{\\theta} = \\frac{1}{N} \\sum_N x_i = \\frac{13}{20}$$\n",
    "\n",
    "也可以从中计算方差。\n",
    "\n",
    "矩估计的方法可以证明是一致的，但不一定有效，并且会给出参数空间之外的估计。\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "参数估计的另一种方法遵循这样一个假设，即我们的数据来自一个群体的独立且同分布的观察结果。我们的目标是找到一个 $\\theta$ 来最大化我们观察到这些数据的可能性。\n",
    "\n",
    "似然函数定义为观察数据的联合概率：\n",
    "\n",
    "$$\\mathcal{L}(\\theta|x_1 ... x_n) = \\prod_{i=1}^n f(x_i | \\theta)$$\n",
    "\n",
    "我们的工作就是求解：\n",
    "\n",
    "\\\\(\\frac{d}{d\\theta}\\mathcal{L}(\\theta|{x})=0\\\\) 确保它是最大值而不是在边界上。\n",
    "\n",
    "如果我们回到 20 次抛 13 个正面的抛硬币示例，我们首先设置似然函数并求关于 \\\\(\\theta\\\\)导数。\n",
    "\n",
    "\\\\(\\mathcal{L}(\\theta|x_1 ... x_n) = \\prod_{i=1}^n \\theta^x(1-\\theta)^{(1-x)}\\\\)\n",
    "\n",
    "请注意，通常需要将似然转换为对数似然，以避免因拥有大量数据而导致计算困难。\n",
    "\n",
    "\\\\(ln \\mathcal{L}(\\theta|x_1 ... x_n) = (\\sum_{i=1}^n x_i) ln \\theta + (\\sum_{i=1}^n (1-x_i)) ln (1-\\theta)\\\\)\n",
    "\n",
    "将对 \\\\(\\theta\\\\) 导数设置为零，我们得到\n",
    "\n",
    "\\\\((\\sum_{i=1}^n x_i)\\frac{1}{\\hat{\\theta}} -(\\sum_{i=1}^n (1-x_i))\\frac{1}{1-\\hat{\\theta}}\\\\) = 0\n",
    "\n",
    "求解 \\\\(\\hat{\\theta}\\\\), 有\n",
    "\n",
    "$$\\hat{\\theta} = \\frac{1}{n}\\sum_{i=1}^n x_i = \\bar{x}$$\n",
    "\n",
    "可以看到和之前的 \\\\(\\frac{13}{20}\\\\) 结果是匹配的。\n",
    "\n",
    "MLE 可以被证明是一个一致的估计量，但可能有偏差。在操作上，可能在计算上很昂贵，但提供了一个有用的事实，即**参数的任何函数也是 MLE 的函数**（后面有用），即invariant to transformation。\n",
    "\n",
    "补充实例：https://www.coursera.org/learn/compstatsintro/lecture/xnuDc/mle-estimation-using-a-beta-distribution\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model\n",
    "\n",
    "https://www.coursera.org/learn/compstatsintro/lecture/FLZND/gaussian-mixture-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum a posteriori estimate\n",
    "\n",
    "在后面我们将更详细地讨论 MAP 估计，现在，我们可以保留这一点，因为 MAP 估计是使用先验或附加信息的增强 MLE。该过程与查找 MLE 的过程相同，但是，我们通过以下方式添加了其他信息：\n",
    "    \n",
    "$$\\hat{\\theta}_{MAP} = arg max_{\\theta} \\mathcal{L}(\\theta|x_1 ... x_n) \\ast \\pi (\\theta)$$\n",
    "\n",
    "\\\\(\\pi (\\theta)\\\\) 是我们的先验或附加信息。\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric Methods：Kernel Density Estimation\n",
    "\n",
    "https://www.coursera.org/learn/compstatsintro/lecture/z3vh0/non-parametric-methods-kernel-density-estimation\n",
    "\n",
    "最后简单补充非参数估计概率密度函数的方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
